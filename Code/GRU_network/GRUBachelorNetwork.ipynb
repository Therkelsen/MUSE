{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NveoGaHv4S_G",
    "outputId": "a40a2f13-dfce-462e-ce8a-f1f8b148339c"
   },
   "outputs": [],
   "source": [
    "# Tensorflow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras.layers import Input # for instantiating a keras tensor\n",
    "from keras.layers import GRU, Dense, GRU, Dropout, concatenate, Activation, Concatenate, Flatten, BatchNormalization# for creating layers inside the Neural Network\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.initializers import he_normal\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "\n",
    "# Sklearn\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__) # print version\n",
    "from sklearn.preprocessing import MinMaxScaler # for feature scaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Visualization\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "print('plotly: %s' % plotly.__version__) # print version\n",
    "\n",
    "import scipy.io\n",
    "from scipy.interpolate import interp1d\n",
    "print('scipy: %s' % scipy.__version__) # print version\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data posprocessing</h1>\n",
    "<h3>Concatinating data from several csv files to one</h3>\n",
    "This section synchronizes and concatinates the EIM and kinematic data through unix time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window averaging helper function. Check report for details\n",
    "def rolling_mean(input_signal):\n",
    "    output_signal = input_signal.copy()\n",
    "    buffer = len(input_signal) // 50\n",
    "    running_sum = 0.0\n",
    "\n",
    "    for i in range(len(input_signal)):\n",
    "        running_sum += input_signal[i]\n",
    "\n",
    "        if i < buffer:\n",
    "            output_signal[i] = running_sum / float(i + 1)\n",
    "        else:\n",
    "            running_sum -= input_signal[i - buffer]\n",
    "            output_signal[i] = running_sum / float(buffer)\n",
    "\n",
    "    return output_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Pandas options to display more columns\n",
    "pd.options.display.max_columns=150\n",
    "\n",
    "# Loading data and adding headers 'ElbowAngles' and 'Time'\n",
    "# NB! The concatination is for now a manual process, where the sample directory for\n",
    "# elbow angles and EIM data must be specified for each sample pr run of this cell!\n",
    "kinematic_data_dir = 'MoCap/test_on_simon/24_45deg_hold_6kg/elbow_angles.csv'\n",
    "eim_data_dir = 'MoCap/test_on_simon/24_45deg_hold_6kg/filtered_output_data.csv'\n",
    "df_kin=pd.read_csv(kinematic_data_dir, encoding='utf-8', names=[\"ElbowAngles\", \"Time\"])\n",
    "df_eim=pd.read_csv(eim_data_dir, encoding='utf-8')\n",
    "\n",
    "# Stripping data of unwanted delimiters and converting to float\n",
    "df_kin['ElbowAngles'] = df_kin['ElbowAngles'].str.strip('[]').astype(float)\n",
    "df_kin['Time'] = df_kin['Time'].str.strip('[]').astype(str)\n",
    "df_kin['Time'] = df_kin['Time'].str.strip('\\'').astype(float)\n",
    "\n",
    "# Extracting Unix time\n",
    "kin_unix = df_kin['Time'].values\n",
    "eim_unix = df_eim['Time'].values\n",
    "\n",
    "# Extracting max and min Unix values of kin and using these to figure out where to slice the EIM data\n",
    "kin_min = kin_unix.min()\n",
    "kin_max = kin_unix.max()\n",
    "eim_min = eim_unix.min()\n",
    "eim_max = eim_unix.max()\n",
    "\n",
    "# Filter EIM data based on kinematic Unix time range\n",
    "df_eim = df_eim[(df_eim['Time'] >= kin_min) & (df_eim['Time'] <= kin_max-1.5)]\n",
    "\n",
    "# Creating timestamps. EIM samples at 1000hZ, so 1 timestamp will correspond to 1ms\n",
    "df_eim['Timestamp'] = np.linspace(0, (len(df_eim) - 1), len(df_eim))\n",
    "df_kin['Timestamp'] = np.linspace(0, (len(df_kin) - 1), len(df_kin))\n",
    "\n",
    "# Extract timestamps and kinematic data\n",
    "kinematic_timestamps = df_kin['Timestamp'].values\n",
    "kinematic_data = df_kin['ElbowAngles'].values\n",
    "eim_timestamps = df_eim['Timestamp'].values\n",
    "\n",
    "# Interpolation of the kinematic data to match the EIM data\n",
    "shape = eim_timestamps.shape\n",
    "kinematic_interpolated = np.empty(shape)\n",
    "kin_idx = 0\n",
    "step = math.floor(len(eim_timestamps)/len(kinematic_timestamps))\n",
    "step_remainder = len(eim_timestamps)/len(kinematic_timestamps) - step\n",
    "step_temp = 0\n",
    "temp = 0\n",
    "\n",
    "# Linear interpolation done by averaging between two points. Each data step is done based \n",
    "# on the integer difference between the lenghts of the datasets. For increased accuracy, \n",
    "# whenever the remainder of the division becomes equal to or greater than 1, 1 is added \n",
    "# to the step, and withdrawn from the counter.\n",
    "for i in range(0, len(kinematic_data), 1):\n",
    "    kinematic_interpolated[kin_idx] = kinematic_data[i]\n",
    "    if i < len(kinematic_data)-1:\n",
    "        temp = kinematic_data[i+1]\n",
    "        for j in range(kin_idx + 1, kin_idx+step, 1):\n",
    "            kinematic_interpolated[j] = (kinematic_interpolated[j-1] + temp) / 2\n",
    "    else:\n",
    "        temp = kinematic_data[i]\n",
    "        for j in range(kin_idx + 1, len(eim_timestamps), 1):\n",
    "            kinematic_interpolated[j] = (kinematic_interpolated[j-1] + temp) / 2\n",
    "\n",
    "        step_temp = step_temp+step_remainder\n",
    "    if step_temp >= 1:\n",
    "        kin_idx = kin_idx + step + 1\n",
    "        step_temp = step_temp - 1\n",
    "    else:\n",
    "        kin_idx = kin_idx + step\n",
    "\n",
    "\n",
    "# Interpolate kinematic data to match EIM timestamps. Lines are drawn between the spread out data. \n",
    "# Missing values are being extrapolated\n",
    "kinematic_interpolated = interp1d(eim_timestamps, kinematic_interpolated, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "# The interpolated data is being saved to the JointAngle column in the eim_data\n",
    "df_eim['JointAngle'] = kinematic_interpolated(eim_timestamps)\n",
    "\n",
    "\n",
    "# Calculating rolling mean\n",
    "df_eim['RollingAverageMag'] = rolling_mean(df_eim['EIMMagnitude'])\n",
    "df_eim['RollingAveragePhase'] = rolling_mean(df_eim['EIMPhase'])\n",
    "df_eim['RollingStdEIM'] = df_eim['EIMMagnitude'].rolling(100).std()\n",
    "std_value=df_eim['RollingStdEIM'][99]\n",
    "df_eim['RollingStdEIM'].fillna(value=std_value, inplace=True) \n",
    "\n",
    "\n",
    "\n",
    "# Saving the result to csv, where all samples are gonna be saved. Probs the user for sample number and weight\n",
    "# If file does not exist it will create one.\n",
    "# NB! One sample is saved in the file pr run of this cell! Check the visualization for sanity check after each run.\n",
    "# If sample needs further processing or if you accidentally saves unwanted data in the main csv file, you'll have\n",
    "# to manually remove that sample from the main csv.\n",
    "df_final = df_eim[['Sample', 'EIMMagnitude', 'EIMPhase', 'JointAngle', 'Mass', 'Time', 'RollingAverageMag', 'RollingAveragePhase']]\n",
    "df_eim_kin = 'all_samples.csv'\n",
    "\n",
    "if(os.path.isfile(df_eim_kin)):\n",
    "    sample_number = input(\"Please provide the sample number and press enter:\")\n",
    "    mass = input(\"Please provide the mass used in the current sample:\")\n",
    "    df_final = df_final.assign(Sample=sample_number)\n",
    "    df_final = df_final.assign(Mass=mass)\n",
    "    df_final.to_csv(df_eim_kin, mode='a', index= False, header=False)\n",
    "else:\n",
    "    sample_number = input(\"Please provide the sample number and press enter:\")\n",
    "    mass = input(\"Please provide the mass used in the current sample:\")\n",
    "    df_final = df_final.assign(Sample=sample_number)\n",
    "    df_final = df_final.assign(Mass=mass)\n",
    "    df_final.to_csv(df_eim_kin, mode='w', index= False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming df_eim is your DataFrame\n",
    "plt.plot(df_eim['Timestamp'], df_eim['JointAngle'], marker='o')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('ElbowAngles')\n",
    "plt.title('Line Plot of ElbowAngles')\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(df_eim['Timestamp'], df_eim['EIMMagnitude'], marker='o')\n",
    "# plt.xlabel('Timestamp')\n",
    "# plt.ylabel('EIMMagnitude')\n",
    "# plt.title('Line Plot of EIMMagnitude')\n",
    "# plt.show()\n",
    "\n",
    "plt.plot(df_eim['Timestamp'], df_eim['RollingAverageMag'], marker='o')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('RollingAverageEIM')\n",
    "plt.title('Line Plot of RollingAverageEIM')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(df_eim['Timestamp'], df_eim['RollingStdEIM'], marker='o')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('RollingStdEIM')\n",
    "plt.title('Line Plot of RollingStdEIM')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(df_eim['Timestamp'], df_eim['RollingAveragePhase'], marker='o')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('EIMPhase')\n",
    "plt.title('Line Plot of EIMPhase')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load data</h1>\n",
    "Once you have concatinated all samples into one csv file, you are good to load that file and start the proces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWjTSWVM4_5x"
   },
   "outputs": [],
   "source": [
    "dir_all = 'all_samples.csv'\n",
    "df_all=pd.read_csv(dir_all, encoding='utf-8')\n",
    "grouped = df_all.groupby('Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature extraction</h1>\n",
    "Adjust as needed, whatever features you think might be interesting based on your domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_v5zoN_47UEB"
   },
   "outputs": [],
   "source": [
    "# Set Pandas options to display more columns\n",
    "pd.options.display.max_columns=150\n",
    "\n",
    "# Calculate the median for each group\n",
    "median_values = grouped[['EIMMagnitude', 'EIMPhase']].apply(lambda group: group[['EIMMagnitude', 'EIMPhase']].agg(['min', 'max']).median())\n",
    "\n",
    "# Calculate the mean for each group\n",
    "mean_values = grouped[['EIMMagnitude', 'EIMPhase']].mean()\n",
    "\n",
    "# Calculate the standard deviation for each group\n",
    "standard_deviations = grouped[['EIMMagnitude', 'EIMPhase']].std()\n",
    "\n",
    "# Calculate the variance for each group\n",
    "variance_values = grouped[['EIMMagnitude', 'EIMPhase']].var()\n",
    "\n",
    "# Calculate the kurtosis for each group\n",
    "kurtosis_values = grouped[['EIMMagnitude', 'EIMPhase']].apply(pd.DataFrame.kurtosis)\n",
    "\n",
    "# Reset the index to get the 'Sample' column back\n",
    "median_values.reset_index(inplace=True)\n",
    "mean_values.reset_index(inplace=True)\n",
    "standard_deviations.reset_index(inplace=True)\n",
    "variance_values.reset_index(inplace=True)\n",
    "kurtosis_values.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to indicate they represent the median\n",
    "median_values.columns = ['Sample', 'MedianEIMMagnitude', 'MedianEIMPhase']\n",
    "mean_values.columns = ['Sample', 'MeanEIMMagnitude', 'MeanEIMPhase']\n",
    "standard_deviations.columns = ['Sample', 'StdEIMMagnitude', 'StdEIMPhase']\n",
    "variance_values.columns = ['Sample', 'VarEIMMagnitude', 'VarEIMPhase']\n",
    "kurtosis_values.columns = ['Sample', 'KurtEIMMagnitude', 'KurtEIMPhase']\n",
    "\n",
    "# Merge the median and mean values back into the original DataFrame based on the 'Sample' column\n",
    "df_all = df_all.merge(median_values, on='Sample', how='left')\n",
    "df_all = df_all.merge(mean_values, on='Sample', how='left')\n",
    "df_all = df_all.merge(standard_deviations, on='Sample', how='left')\n",
    "df_all = df_all.merge(variance_values, on='Sample', how='left')\n",
    "df_all = df_all.merge(kurtosis_values, on='Sample', how='left')\n",
    "\n",
    "# Calculate rate of change for each group\n",
    "df_all['ROCEIMMagnitude'] = df_all['RollingAverageMag'].pct_change()\n",
    "df_all['ROCEIMPhase'] = df_all['RollingAveragePhase'].pct_change()\n",
    "\n",
    "#Filling NaN values out with the first mean value in the series\n",
    "ROC_value=df_all['ROCEIMMagnitude'][1]\n",
    "df_all['ROCEIMMagnitude'].fillna(value=ROC_value, inplace=True)\n",
    "ROC_value=df_all['ROCEIMPhase'][1]\n",
    "df_all['ROCEIMPhase'].fillna(value=ROC_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "OBEa3elc7e75",
    "outputId": "e9585139-2963-43e1-c602-40fcbdc07b9a"
   },
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "AcEI6Kyw7ioa",
    "outputId": "ddc895f9-57a0-45a1-cbf2-f9bea4935e54"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assuming your data is stored in a pandas DataFrame named 'df'\n",
    "# Filter the data for the last 10 samples\n",
    "df_last_10_samples = df_all[df_all['Sample'] >= 89]\n",
    "\n",
    "# Create a scatter plot for EIMMagnitude and JointAngle\n",
    "fig = go.Figure()\n",
    "\n",
    "for sample in df_last_10_samples['Sample'].unique():\n",
    "    sample_data = df_last_10_samples[df_last_10_samples['Sample'] == sample]\n",
    "    fig.add_trace(go.Scatter(x=sample_data.index, y=sample_data['EIMMagnitude'],\n",
    "                             mode='lines+markers', name=f'Sample {sample} - EIMMagnitude'))\n",
    "    fig.add_trace(go.Scatter(x=sample_data.index, y=sample_data['JointAngle'],\n",
    "                             mode='lines+markers', name=f'Sample {sample} - JointAngle'))\n",
    "\n",
    "fig.update_layout(title='EMG and Kinematic Data for the last 10 Samples',\n",
    "                  xaxis_title='Time Steps', yaxis_title='Value')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKbJlbytH4Ox"
   },
   "source": [
    "<h1>Create test set</h1>\n",
    "These will be extracted from dataframe after normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NI9QcHwRH3d2"
   },
   "outputs": [],
   "source": [
    "df_all_grouped = df_all.groupby(['Sample'])\n",
    "\n",
    "specific_samples = [23, 38, 47, 50, 89, 98]\n",
    "\n",
    "# Create an empty DataFrame to store the selected samples\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Iterate through the specific samples and extract them for testing.\n",
    "for sample_value in specific_samples:\n",
    "    if sample_value in df_all_grouped.groups:\n",
    "        df_test = pd.concat([df_test, df_all_grouped.get_group(sample_value)])\n",
    "\n",
    "# Save the test data to csv\n",
    "# df_test.to_csv('/content/drive/MyDrive/NeuralNetwork/test_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "DaPYpkoVInvT",
    "outputId": "0b94348a-2138-493b-bf97-a5139793e3b0"
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "YEsvPKahKxsg",
    "outputId": "2f1ef113-dfab-4519-c145-c7115afb3590"
   },
   "outputs": [],
   "source": [
    "# Define the columns you want to normalize\n",
    "features_to_normalize = ['EIMMagnitude', 'EIMPhase', 'RollingAverageMag', 'RollingAveragePhase',\n",
    "                        'MedianEIMMagnitude', 'MedianEIMPhase', 'MeanEIMMagnitude',\n",
    "                        'MeanEIMPhase', 'StdEIMMagnitude', 'StdEIMPhase', 'VarEIMMagnitude',\n",
    "                        'VarEIMPhase', 'KurtEIMMagnitude', 'KurtEIMPhase', 'ROCEIMMagnitude',\n",
    "                        'ROCEIMPhase']\n",
    "\n",
    "targets_to_normalize = ['Mass', 'JointAngle']\n",
    "\n",
    "columns_to_use = ['EIMMagnitude', 'EIMPhase', 'RollingAverageMag', 'RollingAveragePhase',\n",
    "                        'MedianEIMMagnitude', 'MedianEIMPhase', 'MeanEIMMagnitude',\n",
    "                        'MeanEIMPhase', 'StdEIMMagnitude', 'StdEIMPhase', 'VarEIMMagnitude',\n",
    "                        'VarEIMPhase', 'KurtEIMMagnitude', 'KurtEIMPhase', 'ROCEIMMagnitude',\n",
    "                        'ROCEIMPhase', 'Mass', 'JointAngle']\n",
    "\n",
    "# Extract the 'Sample' column to append after normalization\n",
    "sample_column = df_all['Sample'].values\n",
    "\n",
    "# Create a copy of an original dataframe\n",
    "df2=df_all.drop(['Time', 'Sample'], axis=1)\n",
    "\n",
    "# Extracting mean and standard deviation for mean normalization\n",
    "df_mean = df2.mean()\n",
    "df_std = df2.std()\n",
    "normalized_df=(df2-df_mean)/df_std\n",
    "\n",
    "# Add the sample column again\n",
    "normalized_df['Sample'] = sample_column\n",
    "\n",
    "# Save means and std to CSV\n",
    "# df_mean.to_csv('/content/drive/MyDrive/NeuralNetwork/means.csv', header=True)\n",
    "# df_std.to_csv('/content/drive/MyDrive/NeuralNetwork/std_devs.csv', header=True)\n",
    "\n",
    "# Show a snaphsot of data\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "BnCWzFA0jerb",
    "outputId": "cc100fd3-7c44-4100-9047-a8005ba43df5"
   },
   "outputs": [],
   "source": [
    "df_org = normalized_df*df_std+df_mean\n",
    "df_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8XuB5fWFyNr",
    "outputId": "f8ff9e31-ca35-4a55-9179-f94968963349"
   },
   "outputs": [],
   "source": [
    "# Display the original DataFrame length\n",
    "print(\"Original DataFrame Length:\", len(normalized_df))\n",
    "\n",
    "# Remove the extracted samples from the original DataFrame\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 23].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 38].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 47].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 50].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 89].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 98].index, inplace = True)\n",
    "\n",
    "# Display the modified original DataFrame length\n",
    "print(\"\\nModified Original DataFrame Length:\", len(normalized_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7JXTqxBgNbm",
    "outputId": "5b77d219-0719-4a57-98a5-6b6bc90a9195"
   },
   "outputs": [],
   "source": [
    "# Check if test samples have been removed\n",
    "for sample_value in specific_samples:\n",
    "  print(sample_value in normalized_df['Sample'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "XyYIByqC9CHL",
    "outputId": "f4004b28-14d9-4995-b666-5e4840b67018"
   },
   "outputs": [],
   "source": [
    "normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create the sequences</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQGtLwCnYw3G",
    "outputId": "c867e4e4-8b12-4ae1-fd7d-354afd285fa2"
   },
   "outputs": [],
   "source": [
    "# Set number of features and sequence lengths\n",
    "num_features = 16\n",
    "sequence_length = 30\n",
    "\n",
    "columns_x = ['EIMMagnitude', 'EIMPhase', 'RollingAverageMag', 'RollingAveragePhase',\n",
    "            'MedianEIMMagnitude', 'MedianEIMPhase', 'MeanEIMMagnitude',\n",
    "            'MeanEIMPhase', 'StdEIMMagnitude', 'StdEIMPhase', 'VarEIMMagnitude',\n",
    "            'VarEIMPhase', 'KurtEIMMagnitude', 'KurtEIMPhase', 'ROCEIMMagnitude',\n",
    "            'ROCEIMPhase']\n",
    "\n",
    "columns_y = ['JointAngle', 'Mass']\n",
    "\n",
    "# Group the data by the 'Sample' column\n",
    "df_grouped = normalized_df.groupby(['Sample'])\n",
    "\n",
    "# Create sequences for each group\n",
    "X_seq, y_seq = [], []\n",
    "\n",
    "for group_name, group_data in df_grouped:\n",
    "\n",
    "    group_data_x_temp = group_data[columns_x]\n",
    "    group_data_x = np.array(group_data_x_temp)  # Convert to NumPy array\n",
    "\n",
    "    group_data_temp_y = group_data[columns_y]\n",
    "    group_data_y = np.array(group_data_temp_y)  # Convert to NumPy array\n",
    "\n",
    "    # Create sequences\n",
    "    for i in range(len(group_data) - sequence_length + 1):\n",
    "        X_seq.append(group_data_x[i:i+sequence_length, :])\n",
    "        y_seq.append(group_data_y[i+sequence_length-1, :])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_seq_np = np.array(X_seq)\n",
    "y_seq_np = np.array(y_seq)\n",
    "\n",
    "# Split into training and validation data in a 80/20 ratio. Testing is done with the samples extracted from the dataset earlier\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_seq_np, y_seq_np, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define the network</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAL-p1szwrsx"
   },
   "outputs": [],
   "source": [
    "lr = 0.0002957\n",
    "fc_layer_size1 = 256\n",
    "fc_layer_size2 = 64\n",
    "dropout_val = 0.5\n",
    "recurrent_dropout_val = 0.4\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Build the GRU model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(GRU(units=fc_layer_size1, activation='relu', return_sequences=True,\n",
    "              kernel_initializer=he_normal(seed=seed_value),\n",
    "              kernel_regularizer=l2(0.01),\n",
    "              input_shape=(sequence_length, num_features), name='Input-Layer'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(dropout_val, seed=seed_value))  # Dropout after the first GRU layer\n",
    "\n",
    "model.add(GRU(units=fc_layer_size2, activation='relu',\n",
    "              kernel_initializer=he_normal(seed=seed_value),\n",
    "              kernel_regularizer=l2(0.01),\n",
    "              recurrent_dropout=recurrent_dropout_val, dropout=recurrent_dropout_val))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(dropout_val, seed=seed_value))  # Dropout after the second GRU layer\n",
    "\n",
    "model.add(Dense(units=2, activation='linear'))  # Output layer\n",
    "\n",
    "optimizer = Nadam(learning_rate = lr, beta_1 = 0.9, beta_2 = 0.999, clipvalue = 0.5, clipnorm = 1)  # Clip gradients between -0.5 and 0.5 to address the exploding gradient problem\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_m4B_JGwx7b",
    "outputId": "a55a6674-55f4-4d9d-d512-4886454e22f9"
   },
   "outputs": [],
   "source": [
    "batch = 72\n",
    "num_epochs = 200\n",
    "\n",
    "# Train the model and record the history. Change model_checkpoint name as needed\n",
    "checkpoint_filepath = 'model_checkpoint.h5'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',  # Choose the metric to monitor\n",
    "    patience=10,  # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True,  # Restore model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=num_epochs,\n",
    "                    batch_size=72,\n",
    "                    verbose=1,\n",
    "                    callbacks=[model_checkpoint_callback, early_stopping_callback],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    shuffle=True, # default=True, Boolean (whether to shuffle the training data before each epoch) or str (for 'batch').\n",
    "                    validation_freq=1,\n",
    "                   )\n",
    "\n",
    "# Save the model. Adjust name accordingly\n",
    "model_dir = 'final_model3_Nadam_lz256x64_ES_Drop05.h5'\n",
    "model.save(model_dir)\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss, validation loss, training accuracy, and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Training Loss and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training Accuracy and Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_aqg3CFtVIt"
   },
   "source": [
    "<h1>Hyper parameters tuning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Hyperparameter Sweeps\n",
    "\n",
    "Searching through high dimensional hyperparameter spaces to find the most performant model can get unwieldy very fast. Hyperparameter sweeps provide an organized and efficient way to conduct a battle royale of models and pick the most accurate model. They enable this by automatically searching through combinations of hyperparameter values (e.g. learning rate, batch size, number of hidden layers, optimizer type) to find the most optimal values.\n",
    "\n",
    "In this tutorial we'll see how you can run sophisticated hyperparameter sweeps in 3 easy steps using Weights and Biases.\n",
    "\n",
    "![](https://i.imgur.com/WVKkMWw.png)\n",
    "\n",
    "## Sweeps: An Overview\n",
    "\n",
    "Running a hyperparameter sweep with Weights & Biases is very easy. There are just 3 simple steps:\n",
    "\n",
    "1. **Define the sweep:** we do this by creating a dictionary or a [YAML file](https://docs.wandb.com/library/sweeps/configuration) that specifies the parameters to search through, the search strategy, the optimization metric et all.\n",
    "\n",
    "2. **Initialize the sweep:** with one line of code we initialize the sweep and pass in the dictionary of sweep configurations:\n",
    "`sweep_id = wandb.sweep(sweep_config)`\n",
    "\n",
    "3. **Run the sweep agent:** also accomplished with one line of code, we call wandb.agent() and pass the sweep_id to run, along with a function that defines your model architecture and trains it:\n",
    "`wandb.agent(sweep_id, function=train)`\n",
    "\n",
    "And voila! That's all there is to running a hyperparameter sweep! In the notebook below, we'll walk through these 3 steps in more detail.\n",
    "\n",
    "\n",
    "We highly encourage you to fork this notebook, tweak the parameters, or try the model with your own dataset!\n",
    "\n",
    "## Resources\n",
    "- [Sweeps docs →](https://docs.wandb.com/library/sweeps)\n",
    "- [Launching from the command line →](https://www.wandb.com/articles/hyperparameter-tuning-as-easy-as-1-2-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Start out by installing the experiment tracking library and setting up your free W&B account:\n",
    "\n",
    "\n",
    "*   **pip install wandb** – Install the W&B library\n",
    "*   **import wandb** – Import the wandb library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB – Install the W&B library\n",
    "%pip install wandb -q\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, GRU, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop, SGD, Adam, Nadam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.initializers import he_normal\n",
    "from keras.regularizers import l2\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Sklearn\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__) # print version\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab, uncomment following:\n",
    "\n",
    "# from google.colab import drive\n",
    "# import joblib\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "\n",
    "dir_all = '/content/drive/MyDrive/NeuralNetwork/all_samples.csv'\n",
    "df_all=pd.read_csv(dir_all, encoding='utf-8')\n",
    "grouped = df_all.groupby('Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Pandas options to display more columns\n",
    "pd.options.display.max_columns=150\n",
    "\n",
    "# Calculate the median for each group\n",
    "median_values = grouped[['EIMMagnitude', 'EIMPhase']].apply(lambda group: group[['EIMMagnitude', 'EIMPhase']].agg(['min', 'max']).median())\n",
    "\n",
    "# Calculate the mean for each group\n",
    "mean_values = grouped[['EIMMagnitude', 'EIMPhase']].mean()\n",
    "\n",
    "# Calculate the standard deviation for each group\n",
    "standard_deviations = grouped[['EIMMagnitude', 'EIMPhase']].std()\n",
    "\n",
    "# Calculate the variance for each group\n",
    "variance_values = grouped[['EIMMagnitude', 'EIMPhase']].var()\n",
    "\n",
    "# Calculate the kurtosis for each group\n",
    "kurtosis_values = grouped[['EIMMagnitude', 'EIMPhase']].apply(pd.DataFrame.kurtosis)\n",
    "\n",
    "# Reset the index to get the 'Sample' column back\n",
    "median_values.reset_index(inplace=True)\n",
    "mean_values.reset_index(inplace=True)\n",
    "standard_deviations.reset_index(inplace=True)\n",
    "variance_values.reset_index(inplace=True)\n",
    "kurtosis_values.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to indicate they represent the median\n",
    "median_values.columns = ['Sample', 'MedianEIMMagnitude', 'MedianEIMPhase']\n",
    "mean_values.columns = ['Sample', 'MeanEIMMagnitude', 'MeanEIMPhase']\n",
    "standard_deviations.columns = ['Sample', 'StdEIMMagnitude', 'StdEIMPhase']\n",
    "variance_values.columns = ['Sample', 'VarEIMMagnitude', 'VarEIMPhase']\n",
    "kurtosis_values.columns = ['Sample', 'KurtEIMMagnitude', 'KurtEIMPhase']\n",
    "\n",
    "# Merge the median and mean values back into the original DataFrame based on the 'Sample' column\n",
    "df_all = df_all.merge(median_values, on='Sample', how='left')\n",
    "df_all = df_all.merge(mean_values, on='Sample', how='left')\n",
    "df_all = df_all.merge(standard_deviations, on='Sample', how='left')\n",
    "df_all = df_all.merge(variance_values, on='Sample', how='left')\n",
    "df_all = df_all.merge(kurtosis_values, on='Sample', how='left')\n",
    "\n",
    "# Calculate rate of change for each group\n",
    "df_all['ROCEIMMagnitude'] = df_all['RollingAverageMag'].pct_change()\n",
    "df_all['ROCEIMPhase'] = df_all['RollingAveragePhase'].pct_change()\n",
    "\n",
    "#Filling NaN values out with the first mean value in the series\n",
    "ROC_value=df_all['ROCEIMMagnitude'][1]\n",
    "df_all['ROCEIMMagnitude'].fillna(value=ROC_value, inplace=True)\n",
    "ROC_value=df_all['ROCEIMPhase'][1]\n",
    "df_all['ROCEIMPhase'].fillna(value=ROC_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns you want to normalize\n",
    "features_to_normalize = ['EIMMagnitude', 'EIMPhase', 'RollingAverageMag', 'RollingAveragePhase',\n",
    "                        'MedianEIMMagnitude', 'MedianEIMPhase', 'MeanEIMMagnitude',\n",
    "                        'MeanEIMPhase', 'StdEIMMagnitude', 'StdEIMPhase', 'VarEIMMagnitude',\n",
    "                        'VarEIMPhase', 'KurtEIMMagnitude', 'KurtEIMPhase', 'ROCEIMMagnitude',\n",
    "                        'ROCEIMPhase']\n",
    "\n",
    "targets_to_normalize = ['Mass', 'JointAngle']\n",
    "\n",
    "columns_to_use = ['EIMMagnitude', 'EIMPhase', 'RollingAverageMag', 'RollingAveragePhase',\n",
    "                        'MedianEIMMagnitude', 'MedianEIMPhase', 'MeanEIMMagnitude',\n",
    "                        'MeanEIMPhase', 'StdEIMMagnitude', 'StdEIMPhase', 'VarEIMMagnitude',\n",
    "                        'VarEIMPhase', 'KurtEIMMagnitude', 'KurtEIMPhase', 'ROCEIMMagnitude',\n",
    "                        'ROCEIMPhase', 'Mass', 'JointAngle']\n",
    "\n",
    "# Extract the 'Sample' column to append after normalization\n",
    "sample_column = df_all['Sample'].values\n",
    "\n",
    "# Create a copy of an original dataframe\n",
    "df2=df_all.drop(['Time', 'Sample'], axis=1)\n",
    "\n",
    "# Extracting mean and standard deviation for mean normalization\n",
    "df_mean = df2.mean()\n",
    "df_std = df2.std()\n",
    "normalized_df=(df2-df_mean)/df_std\n",
    "\n",
    "# Add the sample column again\n",
    "normalized_df['Sample'] = sample_column\n",
    "\n",
    "# Save means and std to CSV\n",
    "# df_mean.to_csv('/content/drive/MyDrive/NeuralNetwork/means.csv', header=True)\n",
    "# df_std.to_csv('/content/drive/MyDrive/NeuralNetwork/std_devs.csv', header=True)\n",
    "\n",
    "# Show a snaphsot of data\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original DataFrame length\n",
    "print(\"Original DataFrame Length:\", len(normalized_df))\n",
    "\n",
    "# Remove the extracted samples from the original DataFrame\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 23].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 38].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 47].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 50].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 89].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 98].index, inplace = True)\n",
    "\n",
    "# Display the modified original DataFrame length\n",
    "print(\"\\nModified Original DataFrame Length:\", len(normalized_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if test samples have been removed\n",
    "specific_samples = [23, 38, 47, 50, 89, 98]\n",
    "\n",
    "for sample_value in specific_samples:\n",
    "  print(sample_value in normalized_df['Sample'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the Sweep\n",
    "\n",
    "Weights & Biases sweeps give you powerful levers to configure your sweeps exactly how you want them, with just a few lines of code. The sweeps config can be defined as a dictionary or a [YAML file](https://docs.wandb.com/library/sweeps).\n",
    "\n",
    "Let's walk through some of them together:\n",
    "*   **Metric** – This is the metric the sweeps are attempting to optimize. Metrics can take a `name` (this metric should be logged by your training script) and a `goal` (maximize or minimize).\n",
    "*   **Search Strategy** – Specified using the 'method' variable. We support several different search strategies with sweeps.\n",
    "  *   **Grid Search** – Iterates over every combination of hyperparameter values.\n",
    "  *   **Random Search** – Iterates over randomly chosen combinations of hyperparameter values.\n",
    "  *   **Bayesian Search** – Creates a probabilistic model that maps hyperparameters to probability of a metric score, and chooses parameters with high probability of improving the metric. The objective of Bayesian optimization is to spend more time in picking the hyperparameter values, but in doing so trying out fewer hyperparameter values.\n",
    "*   **Stopping Criteria** – The strategy for determining when to kill off poorly peforming runs, and try more combinations faster. We offer several custom scheduling algorithms like [HyperBand](https://arxiv.org/pdf/1603.06560.pdf) and Envelope.\n",
    "*   **Parameters** – A dictionary containing the hyperparameter names, and discreet values, max and min values or distributions from which to pull their values to sweep over.\n",
    "\n",
    "You can find a list of all configuration options [here](https://docs.wandb.com/library/sweeps/configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJHXMdlhtdjb"
   },
   "outputs": [],
   "source": [
    "# Setting the search mode. Choices: grid, random, bayes.\n",
    "# Use random over grid if you have many hyperparemeters to tune, since grid is computational heavy\n",
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "de-EosAZtuAU"
   },
   "outputs": [],
   "source": [
    "# To tell the sweep which metric to optimize and in which direction. Only necesary for bayes, but a good idea regardless\n",
    "metric = {\n",
    "    'name': 'accuracy',\n",
    "    'goal': 'maximize'\n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJ3DHYcEvEgU"
   },
   "outputs": [],
   "source": [
    "# Specifying hyperparameters we need to optimize\n",
    "parameters_dict = {\n",
    "    # 'optimizer': {\n",
    "    #     'values': ['adam', 'nadam', 'sgd', 'rmsprop']\n",
    "    #     },\n",
    "    # 'learning_rate': {\n",
    "    #     # a flat distribution between 0 and 0.1\n",
    "    #     'distribution': 'uniform',\n",
    "    #     'min': 0,\n",
    "    #     'max': 0.1\n",
    "    #     },\n",
    "    # 'batch_size': {\n",
    "    #     # integers between 32 and 256\n",
    "    #     # with evenly-distributed logarithms\n",
    "    #     'distribution': 'q_log_uniform_values',\n",
    "    #     'q': 8,\n",
    "    #     'min': 32,\n",
    "    #     'max': 256,\n",
    "    #     },\n",
    "    # 'fc_layer_size1': {\n",
    "    #     'values': [32, 64, 128, 256]\n",
    "    #     },\n",
    "    # 'fc_layer_size2': {\n",
    "    #     'values': [32, 64, 128, 256]\n",
    "    #     },\n",
    "    # 'dropout': {\n",
    "    #     'values': [0.2, 0.3, 0.4, 0.5]\n",
    "    #     },\n",
    "    'beta_1' : {\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.85,\n",
    "        'max': 0.95\n",
    "        },\n",
    "    'beta_1' : {\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.999,\n",
    "        'max': 0.9999\n",
    "        },\n",
    "    'epsilon' : {\n",
    "        'distribution': 'uniform',\n",
    "        'min': 1e-9,\n",
    "        'max': 1e-7\n",
    "        },\n",
    "    'clipnorm' : {\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.1,\n",
    "        'max': 10\n",
    "        }\n",
    "    # 'reccurent_dropout': {\n",
    "    #     'values': [0.2, 0.3, 0.4, 0.5]\n",
    "    #     },\n",
    "    # 'kernel_regularizer': {\n",
    "    #     # a flat distribution between 0 and 0.1\n",
    "    #     'distribution': 'uniform',\n",
    "    #     'min': 0.01,\n",
    "    #     'max': 0.4\n",
    "    # }\n",
    "\n",
    "\n",
    "    # 'fc_layer_size': {\n",
    "    #     'values': [128, 256, 512]\n",
    "    #     },\n",
    "    # 'dropout': {\n",
    "    #       'values': [0.3, 0.4, 0.5]\n",
    "    #     },\n",
    "    # 'activation': {\n",
    "    #     'values': ['relu', 'elu', 'selu', 'softmax']\n",
    "    #     },\n",
    "    # 'weight_decay': {\n",
    "    #     'values': [0.0005, 0.005, 0.05]\n",
    "    #     }\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wefQAzM53Hip"
   },
   "outputs": [],
   "source": [
    "# For setting values that we don't want to vary in the script.\n",
    "parameters_dict.update({\n",
    "    'epochs': {\n",
    "        'value': 10}\n",
    "    })\n",
    "\n",
    "parameters_dict.update({\n",
    "    'sequence_length': {\n",
    "        'value': 30}\n",
    "    })\n",
    "\n",
    "parameters_dict.update({\n",
    "    'batch_size': {\n",
    "        'value': 72}\n",
    "    })\n",
    "\n",
    "parameters_dict.update({\n",
    "    'learning_rate': {\n",
    "        'value': 0.0002957}\n",
    "    })\n",
    "\n",
    "parameters_dict.update({\n",
    "    'optimizer': {\n",
    "        'value': 'nadam'}\n",
    "    })\n",
    "\n",
    "parameters_dict.update({\n",
    "    'fc_layer_size1': {\n",
    "        'value': 256}\n",
    "    })\n",
    "\n",
    "parameters_dict.update({\n",
    "    'fc_layer_size2': {\n",
    "        'value': 64}\n",
    "    })\n",
    "\n",
    "parameters_dict.update({\n",
    "    'dropout': {\n",
    "        'value': 0.4}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTRh1ZBc1UTn"
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new sweep\n",
    "# Arguments:\n",
    "#     – sweep_config: the sweep config dictionary defined above\n",
    "#     – entity: Set the username for the sweep\n",
    "#     – project: Set the project name for the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, entity=\"muse_ba\", project=\"MUSE_drop_lsize_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Neural Network\n",
    "Before we can run the sweep, let's define a function that creates and trains our neural network.\n",
    "\n",
    "In the function below, we define a simplified version of a VGG19 model in Keras, and add the following lines of code to log models metrics, visualize performance and output and track our experiments easily:\n",
    "*   **wandb.init()** – Initialize a new W&B run. Each run is single execution of the training script.\n",
    "*   **wandb.config** – Save all your hyperparameters in a config object. This lets you use our app to sort and compare your runs by hyperparameter values.\n",
    "*   **callbacks=[WandbCallback()]** – Fetch all layer dimensions, model parameters and log them automatically to your W&B dashboard.\n",
    "*   **wandb.log()** – Logs custom objects – these can be images, videos, audio files, HTML, plots, point clouds etc. Here we use wandb.log to log images of Simpson characters overlaid with actual and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sweep calls this function with each set of hyperparameters\n",
    "def train():\n",
    "    # Default values for hyper-parameters we're going to sweep over\n",
    "    config_defaults = {\n",
    "        'epochs': 10,\n",
    "        'batch_size': 128,\n",
    "        'weight_decay': 0.0005,\n",
    "        'learning_rate': 1e-3,\n",
    "        'activation': 'relu',\n",
    "        'optimizer': 'adam',\n",
    "        'fc_layer_size1': 32,\n",
    "        'fc_layer_size2': 64,\n",
    "        'dropout': 0.2,\n",
    "        'reccurent_dropout': 0.4,\n",
    "        'kernel_regularizer': 0.01,\n",
    "        'momentum': 0.9,\n",
    "        'seed': 42,\n",
    "        'sequence_length': 30,\n",
    "        'beta_1': 0.9,\n",
    "        'beta_2': 0.999,\n",
    "        'clipnorm': 1.0\n",
    "    }\n",
    "\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init(config=config_defaults)\n",
    "\n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    seed_value = 42\n",
    "    np.random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "    # Set number of features and sequence lengths\n",
    "    num_features = 16\n",
    "    sequence_length = config.sequence_length\n",
    "\n",
    "    columns_x = ['EIMMagnitude', 'EIMPhase', 'RollingAverageMag', 'RollingAveragePhase',\n",
    "                'MedianEIMMagnitude', 'MedianEIMPhase', 'MeanEIMMagnitude',\n",
    "                'MeanEIMPhase', 'StdEIMMagnitude', 'StdEIMPhase', 'VarEIMMagnitude',\n",
    "                'VarEIMPhase', 'KurtEIMMagnitude', 'KurtEIMPhase', 'ROCEIMMagnitude',\n",
    "                'ROCEIMPhase']\n",
    "\n",
    "    columns_y = ['JointAngle', 'Mass']\n",
    "\n",
    "    # Group the data by the 'Sample' column\n",
    "    df_grouped = normalized_df.groupby(['Sample'])\n",
    "\n",
    "    # Create sequences for each group\n",
    "    X_seq, y_seq = [], []\n",
    "\n",
    "    for group_name, group_data in df_grouped:\n",
    "\n",
    "        group_data_x_temp = group_data[columns_x]\n",
    "        group_data_x = np.array(group_data_x_temp)  # Convert to NumPy array\n",
    "\n",
    "        group_data_temp_y = group_data[columns_y]\n",
    "        group_data_y = np.array(group_data_temp_y)  # Convert to NumPy array\n",
    "\n",
    "        # Create sequences\n",
    "        for i in range(len(group_data) - sequence_length + 1):\n",
    "            X_seq.append(group_data_x[i:i+sequence_length, :])\n",
    "            y_seq.append(group_data_y[i+sequence_length-1, :])\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X_seq_np = np.array(X_seq)\n",
    "    y_seq_np = np.array(y_seq)\n",
    "\n",
    "    # Split into training and validation data in a 80/20 ratio. Testing is done with the samples extracted from the dataset earlier\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_seq_np, y_seq_np, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    # Build the GRU model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(GRU(units=config.fc_layer_size1, activation='relu', return_sequences=True,\n",
    "                  kernel_initializer=he_normal(seed=seed_value),\n",
    "                  kernel_regularizer=l2(config.kernel_regularizer),\n",
    "                  input_shape=(sequence_length, num_features), name='Input-Layer'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(config.dropout, seed=seed_value))  # Dropout after the first GRU layer\n",
    "\n",
    "    model.add(GRU(units = config.fc_layer_size2, activation='relu',\n",
    "                  kernel_initializer=he_normal(seed=seed_value),\n",
    "                  kernel_regularizer=l2(config.kernel_regularizer),\n",
    "                  recurrent_dropout=config.reccurent_dropout, dropout=config.dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(config.dropout, seed=seed_value))  # Dropout after the second GRU layer\n",
    "\n",
    "    model.add(Dense(units=2, activation='linear'))  # Output layer\n",
    "\n",
    "    # Define the optimizer\n",
    "    if config.optimizer=='sgd':\n",
    "      optimizer = SGD(learning_rate=config.learning_rate, weight_decay=1e-5, momentum=config.momentum, nesterov=True)\n",
    "    elif config.optimizer=='rmsprop':\n",
    "      optimizer = RMSprop(learning_rate=config.learning_rate, weight_decay=1e-5)\n",
    "    elif config.optimizer=='adam':\n",
    "      optimizer = Adam(learning_rate=config.learning_rate, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "    elif config.optimizer=='nadam':\n",
    "      optimizer = Nadam(learning_rate=config.learning_rate, beta_1=config.beta_1, beta_2=config.beta_2, clipnorm=config.clipnorm)\n",
    "\n",
    "    model.compile(loss = \"mean_squared_error\", optimizer = optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=config.batch_size,\n",
    "              epochs=config.epochs,\n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=[WandbCallback(data_type=\"graph\", validation_data=(X_val, y_val)),\n",
    "                          EarlyStopping(patience=10, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the sweep agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new sweep\n",
    "# Arguments:\n",
    "#     – sweep_id: the sweep_id to run - this was returned above by wandb.sweep()\n",
    "#     – function: function that defines your model architecture and trains it\n",
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Sweeps Results\n",
    "\n",
    "## Parallel coordinates plot\n",
    "This plot maps hyperparameter values to model metrics. It’s useful for honing in on combinations of hyperparameters that led to the best model performance.\n",
    "\n",
    "![](https://assets.website-files.com/5ac6b7f2924c652fd013a891/5e190366778ad831455f9af2_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695138341_image.png)\n",
    "\n",
    "## Hyperparameter Importance Plot\n",
    "The hyperparameter importance plot surfaces which hyperparameters were the best predictors of, and highly correlated to desirable values for your metrics.\n",
    "\n",
    "![](https://assets.website-files.com/5ac6b7f2924c652fd013a891/5e190367778ad820b35f9af5_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695757573_image.png)\n",
    "\n",
    "These visualizations can help you save both time and resources running expensive hyperparameter optimizations by honing in on the parameters (and value ranges) that are the most important, and thereby worthy of further exploration.\n",
    "\n",
    "# Next step - Get your hands dirty with sweeps\n",
    "We created a simple training script and [a few flavors of sweep configs](https://github.com/wandb/examples/tree/master/keras-cnn-fashion) for you to play with. We highly encourage you to give these a try. This repo also has examples to help you try more advanced sweep features like [Bayesian Hyperband](https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/us0ifmrf?workspace=user-lavanyashukla), and [Hyperopt](https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/xbs2wm5e?workspace=user-lavanyashukla)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOobT1vQvnkv"
   },
   "source": [
    "<h3>Further training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "jwD00SrIvxfR",
    "outputId": "f6e193a1-7ec0-4f02-cb5a-76ee3c49dc8f"
   },
   "outputs": [],
   "source": [
    "loaded_checkpoint_path = 'final_model_Nadam_lz256x64_ES.h5'\n",
    "\n",
    "# Load the model with custom_objects to recognize the GRU layer\n",
    "loaded_model = load_model(loaded_checkpoint_path)\n",
    "\n",
    "print(\"Model loaded successfully.\")\n",
    "print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_all = 'all_sim_samples.csv'\n",
    "df_all=pd.read_csv(dir_all, encoding='utf-8')\n",
    "grouped = df_all.groupby('Sample')\n",
    "\n",
    "# Set Pandas options to display more columns\n",
    "pd.options.display.max_columns=150\n",
    "\n",
    "# Calculate the median for each group\n",
    "median_values = grouped[['EIMMagnitude', 'EIMPhase']].apply(lambda group: group[['EIMMagnitude', 'EIMPhase']].agg(['min', 'max']).median())\n",
    "\n",
    "# Calculate the mean for each group\n",
    "mean_values = grouped[['EIMMagnitude', 'EIMPhase']].mean()\n",
    "\n",
    "# Calculate the standard deviation for each group\n",
    "standard_deviations = grouped[['EIMMagnitude', 'EIMPhase']].std()\n",
    "\n",
    "# Calculate the variance for each group\n",
    "variance_values = grouped[['EIMMagnitude', 'EIMPhase']].var()\n",
    "\n",
    "# Calculate the kurtosis for each group\n",
    "kurtosis_values = grouped[['EIMMagnitude', 'EIMPhase']].apply(pd.DataFrame.kurtosis)\n",
    "\n",
    "# Reset the index to get the 'Sample' column back\n",
    "median_values.reset_index(inplace=True)\n",
    "mean_values.reset_index(inplace=True)\n",
    "standard_deviations.reset_index(inplace=True)\n",
    "variance_values.reset_index(inplace=True)\n",
    "kurtosis_values.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to indicate they represent the median\n",
    "median_values.columns = ['Sample', 'MedianEIMMagnitude', 'MedianEIMPhase']\n",
    "mean_values.columns = ['Sample', 'MeanEIMMagnitude', 'MeanEIMPhase']\n",
    "standard_deviations.columns = ['Sample', 'StdEIMMagnitude', 'StdEIMPhase']\n",
    "variance_values.columns = ['Sample', 'VarEIMMagnitude', 'VarEIMPhase']\n",
    "kurtosis_values.columns = ['Sample', 'KurtEIMMagnitude', 'KurtEIMPhase']\n",
    "\n",
    "# Merge the median and mean values back into the original DataFrame based on the 'Sample' column\n",
    "df_all = df_all.merge(median_values, on='Sample', how='left')\n",
    "df_all = df_all.merge(mean_values, on='Sample', how='left')\n",
    "df_all = df_all.merge(standard_deviations, on='Sample', how='left')\n",
    "df_all = df_all.merge(variance_values, on='Sample', how='left')\n",
    "df_all = df_all.merge(kurtosis_values, on='Sample', how='left')\n",
    "\n",
    "# Calculate rate of change for each group\n",
    "df_all['ROCEIMMagnitude'] = df_all['RollingAverageMag'].pct_change()\n",
    "df_all['ROCEIMPhase'] = df_all['RollingAveragePhase'].pct_change()\n",
    "\n",
    "#Filling NaN values out with the first mean value in the series\n",
    "ROC_value=df_all['ROCEIMMagnitude'][1]\n",
    "df_all['ROCEIMMagnitude'].fillna(value=ROC_value, inplace=True)\n",
    "ROC_value=df_all['ROCEIMPhase'][1]\n",
    "df_all['ROCEIMPhase'].fillna(value=ROC_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original DataFrame length\n",
    "print(\"Original DataFrame Length:\", len(normalized_df))\n",
    "\n",
    "df_all_grouped = df_all.groupby(['Sample'])\n",
    "\n",
    "specific_samples = [3, 4, 7]\n",
    "\n",
    "# Create an empty DataFrame to store the selected samples\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "# Iterate through the specific samples and extract them for testing.\n",
    "for sample_value in specific_samples:\n",
    "    if sample_value in df_all_grouped.groups:\n",
    "        df_test = pd.concat([df_test, df_all_grouped.get_group(sample_value)])\n",
    "\n",
    "# Save the test data to csv\n",
    "df_test.to_csv('sim_test_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns you want to normalize\n",
    "features_to_normalize = ['EIMMagnitude', 'EIMPhase', 'RollingAverageMag', 'RollingAveragePhase',\n",
    "                        'MedianEIMMagnitude', 'MedianEIMPhase', 'MeanEIMMagnitude',\n",
    "                        'MeanEIMPhase', 'StdEIMMagnitude', 'StdEIMPhase', 'VarEIMMagnitude',\n",
    "                        'VarEIMPhase', 'KurtEIMMagnitude', 'KurtEIMPhase', 'ROCEIMMagnitude',\n",
    "                        'ROCEIMPhase']\n",
    "\n",
    "targets_to_normalize = ['Mass', 'JointAngle']\n",
    "\n",
    "columns_to_use = ['EIMMagnitude', 'EIMPhase', 'RollingAverageMag', 'RollingAveragePhase',\n",
    "                        'MedianEIMMagnitude', 'MedianEIMPhase', 'MeanEIMMagnitude',\n",
    "                        'MeanEIMPhase', 'StdEIMMagnitude', 'StdEIMPhase', 'VarEIMMagnitude',\n",
    "                        'VarEIMPhase', 'KurtEIMMagnitude', 'KurtEIMPhase', 'ROCEIMMagnitude',\n",
    "                        'ROCEIMPhase', 'Mass', 'JointAngle']\n",
    "\n",
    "# Extract the 'Sample' column to append after normalization\n",
    "sample_column = df_all['Sample'].values\n",
    "\n",
    "# Create a copy of an original dataframe\n",
    "df2=df_all.drop(['Time', 'Sample'], axis=1)\n",
    "\n",
    "# Extracting mean and standard deviation for mean normalization\n",
    "df_mean = df2.mean()\n",
    "df_std = df2.std()\n",
    "\n",
    "# Load the training datas mean and std\n",
    "loaded_means = pd.read_csv('means.csv', index_col=0, squeeze=True)\n",
    "loaded_std_devs = pd.read_csv('std_devs.csv', index_col=0, squeeze=True)\n",
    "\n",
    "# Calculating the difference for proper scaling\n",
    "delta_mean = df_mean - loaded_means\n",
    "delta_std = df_std - loaded_std_devs\n",
    "\n",
    "# Adjust the mean\n",
    "adjusted_mean_new = df_mean - delta_mean\n",
    "adjusted_std_new = df_std - delta_std\n",
    "\n",
    "normalized_df=(df2-adjusted_mean_new)/adjusted_std_new\n",
    "\n",
    "# Add the sample column again\n",
    "normalized_df['Sample'] = sample_column\n",
    "\n",
    "# Save means and std to CSV\n",
    "# df_mean.to_csv('/content/drive/MyDrive/NeuralNetwork/means.csv', header=True)\n",
    "# df_std.to_csv('/content/drive/MyDrive/NeuralNetwork/std_devs.csv', header=True)\n",
    "\n",
    "# Show a snaphsot of data\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the extracted samples from the original DataFrame\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 3].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 4].index, inplace = True)\n",
    "normalized_df.drop(normalized_df[normalized_df['Sample'] == 7].index, inplace = True)\n",
    "\n",
    "# Display the modified original DataFrame length\n",
    "print(\"\\nModified Original DataFrame Length:\", len(normalized_df))\n",
    "\n",
    "# Check if test samples have been removed\n",
    "for sample_value in specific_samples:\n",
    "  print(sample_value in normalized_df['Sample'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of features and sequence lengths\n",
    "num_features = 16\n",
    "sequence_length = 30\n",
    "\n",
    "columns_x = ['EIMMagnitude', 'EIMPhase', 'RollingAverageMag', 'RollingAveragePhase',\n",
    "            'MedianEIMMagnitude', 'MedianEIMPhase', 'MeanEIMMagnitude',\n",
    "            'MeanEIMPhase', 'StdEIMMagnitude', 'StdEIMPhase', 'VarEIMMagnitude',\n",
    "            'VarEIMPhase', 'KurtEIMMagnitude', 'KurtEIMPhase', 'ROCEIMMagnitude',\n",
    "            'ROCEIMPhase']\n",
    "\n",
    "columns_y = ['JointAngle', 'Mass']\n",
    "\n",
    "# Group the data by the 'Sample' column\n",
    "df_grouped = normalized_df.groupby(['Sample'])\n",
    "\n",
    "# Create sequences for each group\n",
    "X_seq, y_seq = [], []\n",
    "\n",
    "for group_name, group_data in df_grouped:\n",
    "\n",
    "    group_data_x_temp = group_data[columns_x]\n",
    "    group_data_x = np.array(group_data_x_temp)  # Convert to NumPy array\n",
    "\n",
    "    group_data_temp_y = group_data[columns_y]\n",
    "    group_data_y = np.array(group_data_temp_y)  # Convert to NumPy array\n",
    "\n",
    "    # Create sequences\n",
    "    for i in range(len(group_data) - sequence_length + 1):\n",
    "        X_seq.append(group_data_x[i:i+sequence_length, :])\n",
    "        y_seq.append(group_data_y[i+sequence_length-1, :])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_seq_np = np.array(X_seq)\n",
    "y_seq_np = np.array(y_seq)\n",
    "\n",
    "# Split into training and validation data in a 80/20 ratio. Testing is done with the samples extracted from the dataset earlier\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_seq_np, y_seq_np, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHzrk8eCv-S2"
   },
   "outputs": [],
   "source": [
    "# Freeze the layers of the pre-trained model all except gru_1\n",
    "for layer in model.layers:\n",
    "    if layer.name == 'gru_1':\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "optimizer = Nadam(learning_rate = lr, beta_1 = 0.9, beta_2 = 0.999, clipvalue = 0.5)  # Clip gradients between -0.5 and 0.5 to address the exploding gradient problem\n",
    "loaded_model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYtwCYYZwKl7",
    "outputId": "c47adcaa-fb10-476d-f735-2f4d20efeef0"
   },
   "outputs": [],
   "source": [
    "batch = 72\n",
    "num_epochs = 200\n",
    "\n",
    "# Train the model and record the history. Change model_checkpoint name as needed\n",
    "checkpoint_filepath = 'model_checkpoint.h5'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',  # Choose the metric to monitor\n",
    "    patience=10,  # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True,  # Restore model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "history = loaded_model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=num_epochs,\n",
    "                    batch_size=72,\n",
    "                    verbose=1,\n",
    "                    callbacks=[model_checkpoint_callback, early_stopping_callback],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    shuffle=True, # default=True, Boolean (whether to shuffle the training data before each epoch) or str (for 'batch').\n",
    "                    validation_freq=1,\n",
    "                   )\n",
    "\n",
    "# Save the model. Adjust name accordingly\n",
    "model_dir = 'final_model_Nadam_lz256x64_ES_NewSubj.h5'\n",
    "loaded_model.save(model_dir)\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyUXgH0RsPWn"
   },
   "source": [
    "<h1>Testing on trainings data subject<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvJs9jB-wghP",
    "outputId": "24fcff6c-18e8-4a02-87c1-b74d31d95237"
   },
   "outputs": [],
   "source": [
    "loaded_checkpoint_path = 'final_model_Nadam_lz256x64_ES.h5'\n",
    "\n",
    "# Load the model with custom_objects to recognize the GRU layer\n",
    "loaded_model = load_model(loaded_checkpoint_path)\n",
    "\n",
    "print(\"Model loaded successfully.\")\n",
    "print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "PzDLrClpb9SI",
    "outputId": "3701c2b0-afe8-407c-a612-8ffeb245d38e"
   },
   "outputs": [],
   "source": [
    "# Load the test set\n",
    "dir_test = 'test_samples.csv'\n",
    "df_test=pd.read_csv(dir_test, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_bWBU5_b_1m"
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMlbi4iMX-TP",
    "outputId": "95829221-ee6c-4f9c-dad8-a18c2f365559"
   },
   "outputs": [],
   "source": [
    "# Extract the 'Sample' column to append after normalization\n",
    "sample_column = df_test['Sample'].values\n",
    "\n",
    "# Create a copy of an original dataframe without Time and Sample\n",
    "df_test=df_test.drop(['Time', 'Sample'], axis=1)\n",
    "\n",
    "# Load means and stds back from CSV. Squeeze them into pandas series\n",
    "loaded_means = pd.read_csv('adjusted_means.csv', index_col=0, squeeze=True)\n",
    "loaded_std_devs = pd.read_csv('adjusted_std_devs.csv', index_col=0, squeeze=True)\n",
    "\n",
    "# df_test_normalized=(df_test-df_mean)/df_std\n",
    "df_test_normalized=(df_test-loaded_means)/loaded_std_devs\n",
    "\n",
    "# Add the sample column again\n",
    "df_test_normalized['Sample'] = sample_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdLLnSL-D8Jt"
   },
   "source": [
    "<h3>Sanity check if scale is applied correctly</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "2eoUDNpgoDgZ",
    "outputId": "841a272a-e131-4b7c-c21a-f423449ec331"
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "VrEcfEgPm0EK",
    "outputId": "d36503b6-88db-46fc-d365-5ccd74ca050e"
   },
   "outputs": [],
   "source": [
    "df_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "W-0bP0VvoSCA",
    "outputId": "e795f23a-02fe-4d94-ca17-c5061af2ef61"
   },
   "outputs": [],
   "source": [
    "df_org = df_test_normalized*loaded_std_devs+loaded_means\n",
    "df_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuJompUiTrkG",
    "outputId": "1ae6635e-0cfb-4eba-8521-af4afffcf9ac"
   },
   "outputs": [],
   "source": [
    "# Initialize test sequences\n",
    "X_seq, y_seq = [], []\n",
    "sequence_length = 30\n",
    "\n",
    "df_grouped_test = df_test_normalized.groupby('Sample')\n",
    "\n",
    "for group_name, group_data in df_grouped_test:\n",
    "\n",
    "    group_data_temp = group_data[['EIMMagnitude', 'EIMPhase', 'RollingAverageMag',\n",
    "                                  'RollingAveragePhase', 'MedianEIMMagnitude', 'MedianEIMPhase',\n",
    "                                  'MeanEIMMagnitude', 'MeanEIMPhase', 'StdEIMMagnitude',\n",
    "                                  'StdEIMPhase', 'VarEIMMagnitude', 'VarEIMPhase', 'KurtEIMMagnitude',\n",
    "                                  'KurtEIMPhase', 'ROCEIMMagnitude','ROCEIMPhase']]\n",
    "\n",
    "    group_data_x = np.array(group_data_temp)  # Convert to NumPy array\n",
    "\n",
    "    group_data_temp = group_data[['JointAngle', 'Mass']]\n",
    "    group_data_y = np.array(group_data_temp)  # Convert to NumPy array\n",
    "\n",
    "    # Create sequences (adjust sequence_length as needed)\n",
    "    for i in range(len(group_data) - sequence_length + 1):\n",
    "        X_seq.append(group_data_x[i:i+sequence_length, :])\n",
    "        y_seq.append(group_data_y[i+sequence_length-1, :])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq)\n",
    "\n",
    "# Now you can use the new_model for predictions\n",
    "predictions_scaled = loaded_model.predict(X_seq)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = loaded_model.evaluate(X_seq, y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v52ITjCfMW5Y",
    "outputId": "b8c89534-e830-49ed-ed13-d1a50bba3f1a"
   },
   "outputs": [],
   "source": [
    "# Converting np.arrays to pd.dataframes to make rescaling easier\n",
    "print(predictions_scaled.shape)\n",
    "print(y_seq.shape)\n",
    "predictions_df = pd.DataFrame(predictions_scaled, columns=['JointAngle', 'Mass'])\n",
    "groundtruths_df = pd.DataFrame(y_seq, columns=['JointAngle', 'Mass'])\n",
    "print(predictions_df.shape)\n",
    "print(groundtruths_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFLqKTNf_9Kx"
   },
   "outputs": [],
   "source": [
    "# Isolate the needed means and standard deviations for reversing the scale\n",
    "df_mean_pred = loaded_means[['JointAngle', 'Mass']]\n",
    "df_std_pred = loaded_std_devs[['JointAngle', 'Mass']]\n",
    "\n",
    "# Reversing the scale\n",
    "predictions = predictions_df*df_std_pred+df_mean_pred\n",
    "groundtruths = groundtruths_df*df_std_pred+df_mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "C434GrxRf36_",
    "outputId": "65d68e64-0e12-4cce-9c43-38fb0f5000ca"
   },
   "outputs": [],
   "source": [
    "# Sorting into ground truths and predictions for plotting\n",
    "joint_angle_true = groundtruths['JointAngle']\n",
    "mass_true = groundtruths['Mass']\n",
    "\n",
    "joint_angle_pred = predictions['JointAngle']\n",
    "mass_pred = predictions['Mass']\n",
    "\n",
    "# Plot the time series of Joint Angle\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.ylim([0, 200])\n",
    "plt.plot(joint_angle_true, label='True Joint Angle', linewidth=6)\n",
    "plt.plot(joint_angle_pred, label='Predicted Joint Angle')\n",
    "plt.title('Joint Angle - True vs. Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Joint Angle')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.ylim([-2, 8])\n",
    "plt.plot(mass_true, label='True Mass', linewidth=6)\n",
    "plt.plot(mass_pred, label='Predicted Mass')\n",
    "plt.title('Mass - True vs. Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Mass')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test on different subject</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test = 'sim_test_samples.csv'\n",
    "df_test_new=pd.read_csv(dir_test, encoding='utf-8')\n",
    "grouped = df_test_new.groupby('Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Pandas options to display more columns\n",
    "pd.options.display.max_columns=150\n",
    "\n",
    "# Calculate the median for each group\n",
    "median_values = grouped[['EIMMagnitude', 'EIMPhase']].apply(lambda group: group[['EIMMagnitude', 'EIMPhase']].agg(['min', 'max']).median())\n",
    "\n",
    "# Calculate the mean for each group\n",
    "mean_values = grouped[['EIMMagnitude', 'EIMPhase']].mean()\n",
    "\n",
    "# Calculate the standard deviation for each group\n",
    "standard_deviations = grouped[['EIMMagnitude', 'EIMPhase']].std()\n",
    "\n",
    "# Calculate the variance for each group\n",
    "variance_values = grouped[['EIMMagnitude', 'EIMPhase']].var()\n",
    "\n",
    "# Calculate the kurtosis for each group\n",
    "kurtosis_values = grouped[['EIMMagnitude', 'EIMPhase']].apply(pd.DataFrame.kurtosis)\n",
    "\n",
    "# Reset the index to get the 'Sample' column back\n",
    "median_values.reset_index(inplace=True)\n",
    "mean_values.reset_index(inplace=True)\n",
    "standard_deviations.reset_index(inplace=True)\n",
    "variance_values.reset_index(inplace=True)\n",
    "kurtosis_values.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to indicate they represent the median\n",
    "median_values.columns = ['Sample', 'MedianEIMMagnitude', 'MedianEIMPhase']\n",
    "mean_values.columns = ['Sample', 'MeanEIMMagnitude', 'MeanEIMPhase']\n",
    "standard_deviations.columns = ['Sample', 'StdEIMMagnitude', 'StdEIMPhase']\n",
    "variance_values.columns = ['Sample', 'VarEIMMagnitude', 'VarEIMPhase']\n",
    "kurtosis_values.columns = ['Sample', 'KurtEIMMagnitude', 'KurtEIMPhase']\n",
    "\n",
    "# Merge the median and mean values back into the original DataFrame based on the 'Sample' column\n",
    "df_test_new = df_test_new.merge(median_values, on='Sample', how='left')\n",
    "df_test_new = df_test_new.merge(mean_values, on='Sample', how='left')\n",
    "df_test_new = df_test_new.merge(standard_deviations, on='Sample', how='left')\n",
    "df_test_new = df_test_new.merge(variance_values, on='Sample', how='left')\n",
    "df_test_new = df_test_new.merge(kurtosis_values, on='Sample', how='left')\n",
    "\n",
    "# Calculate rate of change for each group\n",
    "df_test_new['ROCEIMMagnitude'] = df_test_new['RollingAverageMag'].pct_change()\n",
    "df_test_new['ROCEIMPhase'] = df_test_new['RollingAveragePhase'].pct_change()\n",
    "\n",
    "#Filling NaN values out with the first mean value in the series\n",
    "ROC_value=df_test_new['ROCEIMMagnitude'][1]\n",
    "df_test_new['ROCEIMMagnitude'].fillna(value=ROC_value, inplace=True)\n",
    "ROC_value=df_test_new['ROCEIMPhase'][1]\n",
    "df_test_new['ROCEIMPhase'].fillna(value=ROC_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns you want to normalize\n",
    "features_to_normalize = ['EIMMagnitude', 'EIMPhase', 'RollingAverageMag', 'RollingAveragePhase',\n",
    "                        'MedianEIMMagnitude', 'MedianEIMPhase', 'MeanEIMMagnitude',\n",
    "                        'MeanEIMPhase', 'StdEIMMagnitude', 'StdEIMPhase', 'VarEIMMagnitude',\n",
    "                        'VarEIMPhase', 'KurtEIMMagnitude', 'KurtEIMPhase', 'ROCEIMMagnitude',\n",
    "                        'ROCEIMPhase']\n",
    "\n",
    "targets_to_normalize = ['Mass', 'JointAngle']\n",
    "\n",
    "columns_to_use = ['EIMMagnitude', 'EIMPhase', 'RollingAverageMag', 'RollingAveragePhase',\n",
    "                        'MedianEIMMagnitude', 'MedianEIMPhase', 'MeanEIMMagnitude',\n",
    "                        'MeanEIMPhase', 'StdEIMMagnitude', 'StdEIMPhase', 'VarEIMMagnitude',\n",
    "                        'VarEIMPhase', 'KurtEIMMagnitude', 'KurtEIMPhase', 'ROCEIMMagnitude',\n",
    "                        'ROCEIMPhase', 'Mass', 'JointAngle']\n",
    "\n",
    "# Extract the 'Sample' column to append after normalization\n",
    "sample_column = df_test_new['Sample'].values\n",
    "\n",
    "# Create a copy of an original dataframe\n",
    "df2=df_test_new.drop(['Time', 'Sample'], axis=1)\n",
    "\n",
    "# Extracting mean and standard deviation for mean normalization\n",
    "df_mean = df2.mean()\n",
    "df_std = df2.std()\n",
    "\n",
    "# Load the training datas mean and std\n",
    "loaded_means = pd.read_csv('means.csv', index_col=0, squeeze=True)\n",
    "loaded_std_devs = pd.read_csv('std_devs.csv', index_col=0, squeeze=True)\n",
    "\n",
    "# Calculating the difference for proper scaling\n",
    "delta_mean = df_mean - loaded_means\n",
    "delta_std = df_std - loaded_std_devs\n",
    "\n",
    "# Adjust the mean\n",
    "adjusted_mean_new = df_mean - delta_mean\n",
    "adjusted_std_new = df_std - delta_std\n",
    "\n",
    "normalized_df=(df2-adjusted_mean_new)/adjusted_std_new\n",
    "\n",
    "# Add the sample column again\n",
    "normalized_df['Sample'] = sample_column\n",
    "\n",
    "# Save means and std to CSV\n",
    "# adjusted_mean_new.to_csv('adjusted_means.csv', header=True)\n",
    "# adjusted_std_new.to_csv('adjusted_std_devs.csv', header=True)\n",
    "\n",
    "# Show a snaphsot of data\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = normalized_df*adjusted_std_new+adjusted_mean_new\n",
    "df_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize test sequences\n",
    "X_seq, y_seq = [], []\n",
    "sequence_length = 30\n",
    "\n",
    "df_grouped_test = normalized_df.groupby('Sample')\n",
    "\n",
    "for group_name, group_data in df_grouped_test:\n",
    "\n",
    "    group_data_temp = group_data[['EIMMagnitude', 'EIMPhase', 'RollingAverageMag',\n",
    "                                  'RollingAveragePhase', 'MedianEIMMagnitude', 'MedianEIMPhase',\n",
    "                                  'MeanEIMMagnitude', 'MeanEIMPhase', 'StdEIMMagnitude',\n",
    "                                  'StdEIMPhase', 'VarEIMMagnitude', 'VarEIMPhase', 'KurtEIMMagnitude',\n",
    "                                  'KurtEIMPhase', 'ROCEIMMagnitude','ROCEIMPhase']]\n",
    "\n",
    "    group_data_x = np.array(group_data_temp)  # Convert to NumPy array\n",
    "\n",
    "    group_data_temp = group_data[['JointAngle', 'Mass']]\n",
    "    group_data_y = np.array(group_data_temp)  # Convert to NumPy array\n",
    "\n",
    "    # Create sequences (adjust sequence_length as needed)\n",
    "    for i in range(len(group_data) - sequence_length + 1):\n",
    "        X_seq.append(group_data_x[i:i+sequence_length, :])\n",
    "        y_seq.append(group_data_y[i+sequence_length-1, :])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq)\n",
    "\n",
    "# Now you can use the new_model for predictions\n",
    "predictions_scaled = loaded_model.predict(X_seq)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = loaded_model.evaluate(X_seq, y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting np.arrays to pd.dataframes to make rescaling easier\n",
    "print(predictions_scaled.shape)\n",
    "print(y_seq.shape)\n",
    "predictions_df = pd.DataFrame(predictions_scaled, columns=['JointAngle', 'Mass'])\n",
    "groundtruths_df = pd.DataFrame(y_seq, columns=['JointAngle', 'Mass'])\n",
    "print(predictions_df.shape)\n",
    "print(groundtruths_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the needed means and standard deviations for reversing the scale\n",
    "df_mean_pred = adjusted_mean_new[['JointAngle', 'Mass']]\n",
    "df_std_pred = adjusted_std_new[['JointAngle', 'Mass']]\n",
    "\n",
    "# Reversing the scale\n",
    "predictions = predictions_df*df_std_pred+df_mean_pred\n",
    "groundtruths = groundtruths_df*df_std_pred+df_mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting into ground truths and predictions for plotting\n",
    "joint_angle_true = groundtruths['JointAngle']\n",
    "mass_true = groundtruths['Mass']\n",
    "\n",
    "joint_angle_pred = predictions['JointAngle']\n",
    "mass_pred = predictions['Mass']\n",
    "\n",
    "# Plot the time series of Joint Angle\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.ylim([0, 200])\n",
    "plt.plot(joint_angle_true, label='True Joint Angle', linewidth=6)\n",
    "plt.plot(joint_angle_pred, label='Predicted Joint Angle')\n",
    "plt.title('Joint Angle - True vs. Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Joint Angle')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.ylim([-2, 8])\n",
    "plt.plot(mass_true, label='True Mass', linewidth=6)\n",
    "plt.plot(mass_pred, label='Predicted Mass')\n",
    "plt.title('Mass - True vs. Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Mass')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "029e5c7665e4473d92c65f8a051aedd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7966890027040d59e13c564a50dfe75",
      "placeholder": "​",
      "style": "IPY_MODEL_21d2ebccc97e4e378c6ae9a9bc1bf986",
      "value": "0.010 MB of 0.010 MB uploaded\r"
     }
    },
    "0907e867dfe448c5982026bc062de256": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f35b9d10e9134f06824d7c04ad388846",
      "placeholder": "​",
      "style": "IPY_MODEL_4a2c4b6e41ba4147bbea9ef72e46b955",
      "value": "0.010 MB of 0.010 MB uploaded\r"
     }
    },
    "104c0804a6214b639071fa285db01a47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12a60888b3804cd4b733544d8b604ee0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2126c7e2b42040a5936ef67186223a99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a71d203749f5436dbd55cc00d82d809c",
       "IPY_MODEL_3d0e00449fc843ff94965200ca411b6a"
      ],
      "layout": "IPY_MODEL_b71297146b9740d292686bcae89d77b0"
     }
    },
    "21d2ebccc97e4e378c6ae9a9bc1bf986": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2544e3868975421daa44eba9d2571c79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50c500dd8fa7472082438e86f7211a9a",
      "placeholder": "​",
      "style": "IPY_MODEL_36191f320660409fb692703b5cd12874",
      "value": "0.010 MB of 0.010 MB uploaded\r"
     }
    },
    "278b4746547a4e61921b9b7c32fea9be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_029e5c7665e4473d92c65f8a051aedd5",
       "IPY_MODEL_9246a01f0e174f4ebbbaa1f2a5bb4e98"
      ],
      "layout": "IPY_MODEL_6440f6c25a9c42c18040b899a80b9b68"
     }
    },
    "33cf2b8d94af42538393d25123fb1e01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_104c0804a6214b639071fa285db01a47",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_725df52d6853458297262b5ae04cd314",
      "value": 1
     }
    },
    "36191f320660409fb692703b5cd12874": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36d75aaa73a44a02b8845d630e70c751": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3b4c321b6f714c64953513517e4c457b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d0e00449fc843ff94965200ca411b6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdb0d261b04d4d31a0a609534a4417a4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_12a60888b3804cd4b733544d8b604ee0",
      "value": 1
     }
    },
    "3f8ffed5a5e84f958d232a3a49fec995": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f9136856db641deac06d7a7be6568f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48d4723282a947b3a4883230e87f493b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48d7423c880c4890a42eae536ec02f91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48d4723282a947b3a4883230e87f493b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f8ffed5a5e84f958d232a3a49fec995",
      "value": 1
     }
    },
    "4a2c4b6e41ba4147bbea9ef72e46b955": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50c500dd8fa7472082438e86f7211a9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a2fba9228744331ae1ce42ad7d4d80f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8422ead420b4b67ba6ca5140362e160",
       "IPY_MODEL_48d7423c880c4890a42eae536ec02f91"
      ],
      "layout": "IPY_MODEL_f308aa7b2c50440f8beedba1668a5501"
     }
    },
    "5e61922ebfdd4315b9ad1db8ac4e03d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0907e867dfe448c5982026bc062de256",
       "IPY_MODEL_33cf2b8d94af42538393d25123fb1e01"
      ],
      "layout": "IPY_MODEL_3f9136856db641deac06d7a7be6568f8"
     }
    },
    "6215d5d75ae74d22a4b23ab0792eed6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6440f6c25a9c42c18040b899a80b9b68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "725df52d6853458297262b5ae04cd314": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88b3f2d4864242cda51300de54791f61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2544e3868975421daa44eba9d2571c79",
       "IPY_MODEL_dc7d989b08a54632b63bea6a1a997c38"
      ],
      "layout": "IPY_MODEL_c976d2d638414aa99b4b5ce6ca9def5d"
     }
    },
    "9246a01f0e174f4ebbbaa1f2a5bb4e98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea5ab60b71bc471d9fc4c0d58149d8b4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b782436e4f7d4edfa6e031971d603cce",
      "value": 1
     }
    },
    "a71d203749f5436dbd55cc00d82d809c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6215d5d75ae74d22a4b23ab0792eed6a",
      "placeholder": "​",
      "style": "IPY_MODEL_f871e97ce9fb48b9bbffd481544d89c9",
      "value": "0.010 MB of 0.010 MB uploaded\r"
     }
    },
    "a8422ead420b4b67ba6ca5140362e160": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b180d2ce090b4ace98e2794eb02cdc59",
      "placeholder": "​",
      "style": "IPY_MODEL_3b4c321b6f714c64953513517e4c457b",
      "value": "0.012 MB of 0.012 MB uploaded\r"
     }
    },
    "b180d2ce090b4ace98e2794eb02cdc59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b71297146b9740d292686bcae89d77b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b782436e4f7d4edfa6e031971d603cce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7966890027040d59e13c564a50dfe75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c976d2d638414aa99b4b5ce6ca9def5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc7d989b08a54632b63bea6a1a997c38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea43a8142a6641c682868412877fcb19",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36d75aaa73a44a02b8845d630e70c751",
      "value": 1
     }
    },
    "ea43a8142a6641c682868412877fcb19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea5ab60b71bc471d9fc4c0d58149d8b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f308aa7b2c50440f8beedba1668a5501": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f35b9d10e9134f06824d7c04ad388846": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f871e97ce9fb48b9bbffd481544d89c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdb0d261b04d4d31a0a609534a4417a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
